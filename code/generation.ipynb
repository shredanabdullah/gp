{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from colour import Color\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_folder = 'Delicious'\n",
    "html_file_path = os.path.join(main_folder, 'index.html')\n",
    "css_folder_path = os.path.join(main_folder, 'css')\n",
    "js_folder_path = os.path.join(main_folder, 'js')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = {\n",
    "    'topic': ['website', 'web page', 'site', 'online platform', 'internet presence', 'blog', 'ecommerce site', 'portfolio'],\n",
    "    'location': ['in', 'located in', 'at', 'based in', 'headquartered in', 'global', 'regional', 'national', 'local'],\n",
    "    'colors': ['colors', 'color scheme', 'color palette', 'shades', 'hue', 'primary color', 'secondary color', 'accent color', 'gradient'],\n",
    "    'hotline': ['hotline', 'contact', 'phone number', 'customer service', 'support line', 'helpline', 'contact number', 'service hotline']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_css(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        return file.read()\n",
    "\n",
    "def write_css(file_path, content):\n",
    "    with open(file_path, 'w', encoding='utf-8') as file:\n",
    "        file.write(content)\n",
    "\n",
    "def find_colors(css_content):\n",
    "    hex_color_regex = r'#[0-9a-fA-F]{3,6}'\n",
    "    rgb_color_regex = r'rgb\\s?\\(\\s?\\d{1,3}\\s?,\\s?\\d{1,3}\\s?,\\s?\\d{1,3}\\s?\\)'\n",
    "    rgba_color_regex = r'rgba\\s?\\(\\s?\\d{1,3}\\s?,\\s?\\d{1,3}\\s?,\\s?\\d{1,3}\\s?,\\s?\\d?\\.?\\d+\\s?\\)'\n",
    "    \n",
    "    colors = re.findall(f'{hex_color_regex}|{rgb_color_regex}|{rgba_color_regex}', css_content)\n",
    "    return colors\n",
    "\n",
    "def rgba_to_hex(rgba):\n",
    "    match = re.match(r'rgba\\s?\\(\\s?(\\d{1,3})\\s?,\\s?(\\d{1,3})\\s?,\\s?(\\d{1,3})\\s?,\\s?\\d?\\.?\\d+\\s?\\)', rgba)\n",
    "    if match:\n",
    "        r, g, b = map(int, match.groups())\n",
    "        return '#{:02x}{:02x}{:02x}'.format(r, g, b)\n",
    "    return rgba\n",
    "\n",
    "def generate_new_palette(base_color, old_colors):\n",
    "    base = Color(base_color)\n",
    "    new_palette = [base]\n",
    "\n",
    "    for old_color in old_colors[1:]:\n",
    "        if 'rgba' in old_color:\n",
    "            old_color = rgba_to_hex(old_color)\n",
    "        old_c = Color(old_color)\n",
    "        new_c = Color(base_color)\n",
    "        new_c.luminance = old_c.luminance\n",
    "        new_palette.append(new_c)\n",
    "\n",
    "    return new_palette\n",
    "\n",
    "def replace_colors(css_content, old_colors, new_colors):\n",
    "    for old_color, new_color in zip(old_colors, new_colors):\n",
    "        css_content = re.sub(re.escape(old_color), new_color, css_content)\n",
    "    return css_content\n",
    "\n",
    "def get_linked_css_files(html_file_path):\n",
    "    with open(html_file_path, 'r', encoding='utf-8') as file:\n",
    "        soup = BeautifulSoup(file, 'lxml')\n",
    "    css_files = []\n",
    "    for link_tag in soup.find_all('link', rel='stylesheet'):\n",
    "        href = link_tag.get('href')\n",
    "        if href:\n",
    "            if href.startswith('http://') or href.startswith('https://'):\n",
    "                print(f\"Skipping external CSS file: {href}\")\n",
    "            else:\n",
    "                css_files.append(href)\n",
    "    \n",
    "    return css_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modify_html(html_content, details):\n",
    "    try:\n",
    "        html_content = re.sub(r'<title>.*?</title>', f\"<title>{details.get('topic', 'My Website')}</title>\", html_content)\n",
    "        if re.search(r'<h1>.*?</h1>', html_content):\n",
    "            html_content = re.sub(r'<h1>.*?</h1>', f\"<h1>Welcome to our {details.get('topic', 'website')}</h1>\", html_content)\n",
    "        else:\n",
    "            html_content = re.sub(r'<h2>.*?</h2>', f\"<h2>Welcome to our {details.get('topic', 'website')}</h2>\", html_content)\n",
    "        if 'location' in details:\n",
    "            location_html = f\"<p>Location: {details['location']}</p>\"\n",
    "            html_content = re.sub(r'<!-- location -->', location_html, html_content)\n",
    "        if 'hotline' in details:\n",
    "            hotline_html = f\"<p>Hotline: {details['hotline']}</p>\"\n",
    "            html_content = re.sub(r'<!-- hotline -->', hotline_html, html_content)\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred during HTML modification: {str(e)}\")\n",
    "\n",
    "    return html_content\n",
    "def collect_feedback(description, extracted_details, user_feedback):\n",
    "    try:\n",
    "        print(\"Please review the extracted details:\")\n",
    "        print(extracted_details)\n",
    "        corrected_details = {\n",
    "            'topic': 'coffee website',\n",
    "            'location': 'Cairo',\n",
    "            'colors': ['brown', 'cafe'],\n",
    "            'hotline': '19888'\n",
    "        }\n",
    "        updated_details = {**extracted_details, **corrected_details}\n",
    "\n",
    "        return updated_details\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error during feedback collection: {str(e)}\")\n",
    "        return extracted_details \n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "def extract_details_advanced(description):\n",
    "    details = {}\n",
    "    try:\n",
    "        doc = nlp(description)\n",
    "        for ent in doc.ents:\n",
    "            if ent.label_ == 'ORG' and 'topic' not in details:\n",
    "                details['topic'] = ent.text\n",
    "            elif ent.label_ == 'GPE' and 'location' not in details:\n",
    "                details['location'] = ent.text\n",
    "            elif ent.label_ == 'PRODUCT' and 'topic' not in details:\n",
    "                details['topic'] = ent.text\n",
    "        for token in doc:\n",
    "            if token.text.lower() in keywords['colors'] and token.i + 1 < len(doc):\n",
    "                details['primary_color'] = doc[token.i + 1].text\n",
    "            elif token.text.lower() in keywords['hotline'] and token.i + 1 < len(doc):\n",
    "                next_token = doc[token.i + 1]\n",
    "                if next_token.like_num:\n",
    "                    details['hotline'] = next_token.text\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred during advanced detail extraction: {str(e)}\")\n",
    "\n",
    "    return details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please review the extracted details:\n",
      "{'location': 'Cairo', 'primary_color': ','}\n",
      "Skipping external CSS file: https://fonts.googleapis.com/css?family=Satisfy|Bree+Serif|Candal|PT+Sans\n",
      "Error occurred: 'rgb(255, 255, 255)' is not a recognized color.\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    try:\n",
    "        description = \"I want a website about selling coffee, located in Cairo, with brown and cafe colors, and a hotline number 19888.\"\n",
    "        extracted_details = extract_details_advanced(description)\n",
    "        user_feedback = None \n",
    "        updated_details = collect_feedback(description, extracted_details, user_feedback)\n",
    "        with open(html_file_path, 'r', encoding='utf-8') as f:\n",
    "            html_content = f.read()\n",
    "        modified_html = modify_html(html_content, updated_details)\n",
    "        with open(html_file_path, 'w', encoding='utf-8') as f:\n",
    "            f.write(modified_html)\n",
    "        css_files = get_linked_css_files(html_file_path)\n",
    "        for css_file in css_files:\n",
    "            input_css_path = os.path.join(main_folder, css_file)\n",
    "            output_css_path = os.path.join(main_folder, css_file)  \n",
    "        \n",
    "            css_content = read_css(input_css_path)\n",
    "            \n",
    "            old_colors = find_colors(css_content)\n",
    "            \n",
    "            base_color = \"#0000FF\"  \n",
    "            new_palette = generate_new_palette(base_color, old_colors)\n",
    "            new_colors = [color.hex for color in new_palette]\n",
    "            \n",
    "            updated_css_content = replace_colors(css_content, old_colors, new_colors)\n",
    "            \n",
    "            write_css(output_css_path, updated_css_content)\n",
    "        \n",
    "        print(\"Integration completed successfully!\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred: {str(e)}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Website updated successfully.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "import cssutils\n",
    "\n",
    "user_bg_image = input(\"Enter the URL of the background image: \")\n",
    "user_heading = input(\"Enter the main heading text: \")\n",
    "user_paragraph = input(\"Enter the paragraph text: \")\n",
    "\n",
    "\n",
    "main_folder = 'burger-free'\n",
    "html_path = os.path.join(main_folder, 'index.html')\n",
    "css_folder_path = os.path.join(main_folder, 'css')\n",
    "css_path = os.path.join('css', 'style.css')\n",
    "\n",
    "\n",
    "def update_html(html_path, user_bg_image, user_heading, user_paragraph):\n",
    "    with open(html_path, 'r', encoding='utf-8') as file:\n",
    "        soup = BeautifulSoup(file, 'html.parser')\n",
    "    body_tag = soup.find('body')\n",
    "    if body_tag:\n",
    "        body_tag['style'] = f\"background-image: url('{user_bg_image}');\"\n",
    "    h1_tag = soup.find('h1')\n",
    "    if h1_tag:\n",
    "        h1_tag.string = user_heading\n",
    "    p_tag = soup.find('p')\n",
    "    if p_tag:\n",
    "        p_tag.string = user_paragraph\n",
    "    with open(html_path, 'w', encoding='utf-8') as file:\n",
    "        file.write(str(soup))\n",
    "def update_css(css_path, user_color):\n",
    "    with open(css_path, 'r', encoding='utf-8') as file:\n",
    "        css_content = file.read()\n",
    "    parser = cssutils.CSSParser()\n",
    "    stylesheet = parser.parseString(css_content)\n",
    "    \n",
    "    for rule in stylesheet:\n",
    "        if rule.type == rule.STYLE_RULE:\n",
    "            if rule.selectorText == 'body':\n",
    "                rule.style['background-color'] = user_color\n",
    "            elif rule.selectorText == 'header':\n",
    "                rule.style['background'] = user_color\n",
    "    \n",
    "    with open(css_path, 'w', encoding='utf-8') as file:\n",
    "        file.write(stylesheet.cssText.decode('utf-8'))\n",
    "\n",
    "update_html(html_path, user_bg_image, user_heading, user_paragraph)\n",
    "\n",
    "print(\"Website updated successfully.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
